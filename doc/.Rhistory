library("RColorBrewer")
library("RANN")
library("tm")
library("topicmodels")
source("../lib/plotstacked.R")
source("../lib/speechFuncs.R")
print(R.version)
inaug.list=read.csv("../data/inauglist.csv", stringsAsFactors = FALSE)
nomin.list=read.csv("../data/nominlist.csv", stringsAsFactors = FALSE)
farewell.list=read.csv("../data/farewelllist.csv", stringsAsFactors = FALSE)
speech.list=rbind(inaug.list,
nomin.list,
farewell.list)
speech.list$type=c(rep("inaug", nrow(inaug.list)),
rep("nomin", nrow(nomin.list)),
rep("farewell", nrow(farewell.list)))
#speech.url=rbind(inaug,
#                 nomin,
#                 farewell)
#speech.list=cbind(speech.list, speech.url)
# Loop over each row in speech.list
speech.list$fulltext=NA
for(i in seq(nrow(speech.list))) {
#text <- read_html(speech.list$urls[i]) %>% # load the page
#  html_nodes(".displaytext") %>% # isloate the text
#  html_text() # get the text
text.input=readtext(file=paste("../data/fulltext/",
speech.list$type[i],
speech.list$File[i], "-",
speech.list$Term[i], ".txt"))
print(text.input)
speech.list$fulltext[i]=text.input
# Create the file name
#filename <- paste0("../data/fulltext/",
#                   speech.list$type[i],
#                   speech.list$File[i], "-",
#                   speech.list$Term[i], ".txt")
#sink(file = filename) %>% # open file to write
#cat(text)  # write the file
#sink() # close the file
}
packages.used=c("rvest", "tibble", "qdap",
"sentimentr", "gplots", "dplyr",
"tm", "syuzhet", "factoextra",
"beeswarm", "scales", "RColorBrewer",
"RANN", "tm", "topicmodels", "readtext")
# check packages that need to be installed.
packages.needed=setdiff(packages.used,
intersect(installed.packages()[,1],
packages.used))
# install additional packages
if(length(packages.needed)>0){
install.packages(packages.needed, dependencies = TRUE)
}
# load packages
library("rvest")
library("tibble")
# You may need to run
# sudo ln -f -s $(/usr/libexec/java_home)/jre/lib/server/libjvm.dylib /usr/local/lib
# in order to load qdap
library("qdap")
library("sentimentr")
library("gplots")
library("dplyr")
library("tm")
library("syuzhet")
library("factoextra")
library("beeswarm")
library("scales")
library("RColorBrewer")
library("RANN")
library("tm")
library("topicmodels")
source("../lib/plotstacked.R")
source("../lib/speechFuncs.R")
print(R.version)
inaug.list=read.csv("../data/inauglist.csv", stringsAsFactors = FALSE)
nomin.list=read.csv("../data/nominlist.csv", stringsAsFactors = FALSE)
farewell.list=read.csv("../data/farewelllist.csv", stringsAsFactors = FALSE)
speech.list=rbind(inaug.list,
nomin.list,
farewell.list)
speech.list$type=c(rep("inaug", nrow(inaug.list)),
rep("nomin", nrow(nomin.list)),
rep("farewell", nrow(farewell.list)))
#speech.url=rbind(inaug,
#                 nomin,
#                 farewell)
#speech.list=cbind(speech.list, speech.url)
# Loop over each row in speech.list
speech.list$fulltext=NA
for(i in seq(nrow(speech.list))) {
#text <- read_html(speech.list$urls[i]) %>% # load the page
#  html_nodes(".displaytext") %>% # isloate the text
#  html_text() # get the text
text.input=readtext(file=paste("../data/fulltext/",
speech.list$type[i],
speech.list$File[i], "-",
speech.list$Term[i], ".txt"))
print(text.input)
speech.list$fulltext[i]=text.input
# Create the file name
#filename <- paste0("../data/fulltext/",
#                   speech.list$type[i],
#                   speech.list$File[i], "-",
#                   speech.list$Term[i], ".txt")
#sink(file = filename) %>% # open file to write
#cat(text)  # write the file
#sink() # close the file
}
knitr::opts_chunk$set(echo = TRUE)
library(tm)
library(data.table)
library(tidytext)
library(tidyverse)
library(DT)
# load lyrics data
load('../data/lyrics.RData')
# function for removimg leading and trailing whitespace from character strings
leadingWhitespace <- content_transformer(function(x) str_trim(x, side = "both"))
# remove stop words --> I can change these
data("stop_words")
word <- c("lot", "today", "months", "month", "wanna", "wouldnt", "wasnt", "ha", "na", "ooh", "da",
"gonna", "im", "dont", "aint", "wont", "yeah", "la", "oi", "nigga", "fuck",
"hey", "year", "years", "last", "past", "feel")
stop_words <- c(stop_words$word, word)
# clean the data and make a corpus
corpus <- VCorpus(VectorSource(dt_lyrics$lyrics))%>%
tm_map(content_transformer(tolower))%>%
tm_map(removePunctuation)%>%
tm_map(removeWords, character(0))%>%
tm_map(removeWords, stop_words)%>%
tm_map(removeNumbers)%>%
tm_map(stripWhitespace)%>%
tm_map(leadingWhitespace)
packages.used=c("rvest", "tibble", "qdap",
"sentimentr", "gplots", "dplyr",
"tm", "syuzhet", "factoextra",
"beeswarm", "scales", "RColorBrewer",
"RANN", "tm", "topicmodels", "readtext")
# check packages that need to be installed.
packages.needed=setdiff(packages.used,
intersect(installed.packages()[,1],
packages.used))
# install additional packages
if(length(packages.needed)>0){
install.packages(packages.needed, dependencies = TRUE)
}
# load packages
library("rvest")
library("tibble")
# You may need to run
# sudo ln -f -s $(/usr/libexec/java_home)/jre/lib/server/libjvm.dylib /usr/local/lib
# in order to load qdap
library("qdap")
library("sentimentr")
library("gplots")
library("dplyr")
library("tm")
library("syuzhet")
library("factoextra")
library("beeswarm")
library("scales")
library("RColorBrewer")
library("RANN")
library("tm")
library("topicmodels")
source("../lib/plotstacked.R")
source("../lib/speechFuncs.R")
print(R.version)
inaug.list=read.csv("../data/inauglist.csv", stringsAsFactors = FALSE)
nomin.list=read.csv("../data/nominlist.csv", stringsAsFactors = FALSE)
farewell.list=read.csv("../data/farewelllist.csv", stringsAsFactors = FALSE)
speech.list=rbind(inaug.list,
nomin.list,
farewell.list)
speech.list$type=c(rep("inaug", nrow(inaug.list)),
rep("nomin", nrow(nomin.list)),
rep("farewell", nrow(farewell.list)))
#speech.url=rbind(inaug,
#                 nomin,
#                 farewell)
#speech.list=cbind(speech.list, speech.url)
# Loop over each row in speech.list
speech.list$fulltext=NA
for(i in seq(nrow(speech.list))) {
#text <- read_html(speech.list$urls[i]) %>% # load the page
#  html_nodes(".displaytext") %>% # isloate the text
#  html_text() # get the text
text.input=readtext(file=paste("../data/fulltext/",
speech.list$type[i],
speech.list$File[i], "-",
speech.list$Term[i], ".txt"))
print(text.input)
speech.list$fulltext[i]=text.input
# Create the file name
#filename <- paste0("../data/fulltext/",
#                   speech.list$type[i],
#                   speech.list$File[i], "-",
#                   speech.list$Term[i], ".txt")
#sink(file = filename) %>% # open file to write
#cat(text)  # write the file
#sink() # close the file
}
knitr::opts_chunk$set(echo = TRUE)
library(tm)
library(data.table)
library(tidytext)
library(tidyverse)
library(DT)
# load lyrics data
load('../data/lyrics.RData')
# function for removimg leading and trailing whitespace from character strings
leadingWhitespace <- content_transformer(function(x) str_trim(x, side = "both"))
# remove stop words --> I can change these
data("stop_words")
# "today", "months", "month", "wasnt", "wouldnt", "dont", "aint", "wont", "nigga", "fuck", "year", "years", "last", "past", "feel"
word <- c("lot", "wanna", "ha", "na", "ooh", "da", "gonna", "im", "yeah", "la", "oi", "hey", "today", "months", "month", "wasnt", "wouldnt", "dont", "aint", "wont", "nigga", "fuck", "year", "years", "last", "past", "feel")
stop_words <- c(stop_words$word, word)
# clean the data and make a corpus
corpus <- VCorpus(VectorSource(dt_lyrics$lyrics))%>%
tm_map(content_transformer(tolower))%>%
#tm_map(removePunctuation)%>%
tm_map(removeWords, character(0))%>%
tm_map(removeWords, stop_words)%>%
tm_map(removeNumbers)%>%
tm_map(stripWhitespace)%>%
tm_map(leadingWhitespace)
stemmed <- tm_map(corpus, stemDocument) %>%
tidy() %>%
select(text)
dict <- tidy(corpus) %>%
select(text) %>%
unnest_tokens(dictionary, text)
completed <- stemmed %>%
mutate(id = row_number()) %>%
unnest_tokens(stems, text) %>%
bind_cols(dict)
View(dt_lyrics)
# function for removimg leading and trailing whitespace from character strings
leadingWhitespace <- content_transformer(function(x) str_trim(x, side = "both"))
# remove stop words --> I can change these
data("stop_words")
# "today", "months", "month", "wasnt", "wouldnt", "dont", "aint", "wont", "nigga", "fuck", "year", "years", "last", "past", "feel"
word <- c("lot", "wanna", "ha", "na", "ooh", "da", "gonna", "im", "yeah", "la", "oi", "hey", "today", "months", "month", "wasnt", "wouldnt", "dont", "aint", "wont", "nigga", "fuck", "year", "years", "last", "past", "feel")
stop_words <- c(stop_words$word, word)
# clean the data and make a corpus
corpus <- VCorpus(VectorSource(dt_lyrics$lyrics))%>%
tm_map(content_transformer(tolower))%>%
tm_map(removePunctuation)%>%
tm_map(removeWords, character(0))%>%
tm_map(removeWords, stop_words)%>%
tm_map(removeNumbers)%>%
tm_map(stripWhitespace)%>%
tm_map(leadingWhitespace)
# function for removimg leading and trailing whitespace from character strings
leadingWhitespace <- content_transformer(function(x) str_trim(x, side = "both"))
# remove stop words
data("stop_words")
"feel"
word <- c("lot", "wanna", "ha", "na", "ooh", "da", "gonna", "im", "yeah", "la", "oi", "hey", "today", "months", "month", "wasnt", "wouldnt", "dont", "aint", "wont", "nigga", "fuck", "year", "years", "last", "past", "feel")
stop_words <- c(stop_words$word, word)
# clean the data and make a corpus
corpus <- VCorpus(VectorSource(dt_lyrics$lyrics))%>%
tm_map(content_transformer(tolower))%>%
tm_map(removePunctuation)%>%
tm_map(removeWords, character(0))%>%
tm_map(removeWords, stop_words)%>%
tm_map(removeNumbers)%>%
tm_map(stripWhitespace)%>%
tm_map(leadingWhitespace)
stemmed <- tm_map(corpus, stemDocument) %>%
tidy() %>%
select(text)
dict <- tidy(corpus) %>%
select(text) %>%
unnest_tokens(dictionary, text)
completed <- stemmed %>%
mutate(id = row_number()) %>%
unnest_tokens(stems, text) %>%
bind_cols(dict)
completed <- completed %>%
group_by(stems) %>%
count(dictionary) %>%
mutate(word = dictionary[which.max(n)]) %>%
ungroup() %>%
select(stems, word) %>%
distinct() %>%
right_join(completed) %>%
select(-stems)
completed <- completed %>%
group_by(id) %>%
summarise(stemmedwords= str_c(word, collapse = " ")) %>%
ungroup()
dt_lyrics <- dt_lyrics %>%
mutate(id = row_number()) %>%
inner_join(completed)
save(dt_lyrics, file="../output/processed_lyrics.RData")
load('../output/processed_lyrics.RData')
View(dt_lyrics)
```{r}
head(dt_lyrics)
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(echo = TRUE)
packages.used=c("rvest", "tibble",
"sentimentr", "gplots", "dplyr",
"syuzhet", "factoextra",
"beeswarm", "scales", "RColorBrewer",
"RANN", "topicmodels", "stringr")
# check packages that need to be installed.
packages.needed=setdiff(packages.used,
intersect(installed.packages()[,1],
packages.used))
# load packages
library("rvest")
library("tibble")
library("syuzhet")
library("sentimentr")
library("gplots")
library("dplyr")
library("syuzhet")
library("factoextra")
library("beeswarm")
library("scales")
library("RColorBrewer")
library("RANN")
library("topicmodels")
library("stringr")
load('../output/processed_lyrics.RData')
load('../output/processed_lyrics.RData')
head(dt_lyrics)
# load packages
library("word")
# load packages
install.packages("word")
library("word")
for i in length(dt_lyrics$lyrics[1]) {
for i in 1:length(dt_lyrics$lyrics[1]) {
for i in 1:length(dt_lyrics$lyrics[1]) {
for i in 1:length(dt_lyrics$lyrics[1]) {
for i in 1:length(dt_lyrics$lyrics[1]) {
for i in 1:length(dt_lyrics$lyrics[1]) {
for i in 1:length(dt_lyrics$lyrics[1]) {
for i in 1:length(dt_lyrics$lyrics[1]) {
for (i in 1:length(dt_lyrics$lyrics[1])) {
print(word(dt_lyrics$lyrics[1]), start=i)
}
?split
?strsplit
knitr::opts_chunk$set(echo = TRUE)
# load packages
library("rvest")
library("tibble")
library("syuzhet")
library("sentimentr")
library("gplots")
library("dplyr")
library("syuzhet")
library("factoextra")
library("beeswarm")
library("scales")
library("RColorBrewer")
library("RANN")
library("topicmodels")
library("stringr")
load('../output/processed_lyrics.RData')
head(dt_lyrics)
?strsplit
lyrics <- sapply(dt_lyrics$lyrics, strsplit, split=" ")
View(lyrics)
head(lyrics)
head(lyrics[1])
length(lyrics)
for (i in 1:length(lyrics)) {
print(lyrics[i])
}
for(i in 1:length(lyrics[1])){
#sentences=syuzhet::get_sentences(speech.list$fulltext[i])
#if(length(sentences)>0){
emotions=matrix(emotion(lyrics[1][i])$emotion,
nrow=length(lyrics[1]),
byrow=T)
#colnames(emotions)=emotion(sentences[1])$emotion_type
emotions=data.frame(emotions)
emotions=select(emotions,
anticipation,
joy,
surprise,
trust,
anger,
disgust,
fear,
sadness)
}
#for(i in 1:nrow(speech.list)){
sentences=syuzhet::get_sentences(dt_lyrics$lyrics[1])
sentences
emotions=matrix(emotion(sentences)$emotion,
nrow=length(sentences),
byrow=T)
colnames(emotions)=emotion(sentences[1])$emotion_type
emotions=data.frame(emotions)
emotions=select(emotions,
anticipation,
joy,
surprise,
trust,
anger,
disgust,
fear,
sadness)
data_cleaning <- function(x) {
lyrics <- sapply(x$lyrics, str_replace(), pattern="\n", replacement=" ")
}
lyrics <- data_cleaning(lyrics)
lyrics <- data_cleaning(dt_lyrics)
data_cleaning <- function(x) {
lyrics <- sapply(x$lyrics, str_replace, pattern="\n", replacement=" ")
}
data_cleaning <- function(x) {
lyrics <- sapply(x$lyrics, str_replace, pattern="\n", replacement=" ")
lyrics <- sapply(x$lyrics, tolower)
}
lyrics <- data_cleaning(dt_lyrics$lyrics)
data_cleaning <- function(x) {
lyrics <- sapply(x$lyrics, str_replace, pattern="\n", replacement=" ")
lyrics <- sapply(x$lyrics, tolower)
}
lyrics <- data_cleaning(dt_lyrics$lyrics)
lyrics <- data_cleaning(dt_lyrics$lyrics)
lyrics <- data_cleaning(dt_lyrics)
for(i in 1:nrow(dt_lyrics)){
sentences=syuzhet::get_sentences(dt_lyrics$lyrics[1])
if(length(sentences)>0){
emotions=matrix(emotion(sentences)$emotion,
nrow=length(sentences),
byrow=T)
colnames(emotions)=emotion(sentences[1])$emotion_type
emotions=data.frame(emotions)
emotions=select(emotions,
anticipation,
joy,
surprise,
trust,
anger,
disgust,
fear,
sadness)
}
for(i in 1:nrow(dt_lyrics)){
sentences=syuzhet::get_sentences(dt_lyrics$lyrics[1])
if(length(sentences)>0){
emotions=matrix(emotion(sentences)$emotion,
nrow=length(sentences),
byrow=T)
colnames(emotions)=emotion(sentences[1])$emotion_type
emotions=data.frame(emotions)
emotions=select(emotions,
anticipation,
joy,
surprise,
trust,
anger,
disgust,
fear,
sadness)
}
}
knitr::opts_chunk$set(echo = TRUE)
# load packages
library("sentimentr")
library("ggplot2")
library("plyr")
library("dplyr")
library("stringr")
library("tidyr")
library("RColorBrewer")
library("reshape")
library("Rmisc")
library("CGPfunctions")
library("Hmisc")
library("qdap")
library("tm")
# load data that was processed by Text_Processing.Rmd
load('../output/processed_lyrics.RData')
# function to clean the lyrics. Didn't want to use stemmed words because this only retains one copy of each word that appears
lyrics_cleaning <- function(x) {
x <- bracketX(x)
x <- replace_abbreviation(x)
x <- replace_symbol(x)
x <- removePunctuation(x)
x <- removeWords(x, character(0))
x <- replace_number(x)
x <- stripWhitespace(x)
x <- str_trim(x, side = "both")
x <- tolower(x)
return(x)
}
#removing all songs where the year is before 1900
dt_lyrics <- dt_lyrics[dt_lyrics$year > 1900,]
# looking at the number of songs associated with each genre
for (i in 1:length(unique(dt_lyrics$genre))) {
print(paste(unique(dt_lyrics$genre)[i], ":", nrow(dt_lyrics[dt_lyrics$genre == unique(dt_lyrics$genre)[i],])))
}
# selecting the genres that contain more than 2000 songs and will therefore show more robust results
genres_to_keep <- c("Hip-Hop", "Pop", "Metal", "Rock", "Country", "Jazz", "Electronic", "R&B")
dt_lyrics <- dt_lyrics[dt_lyrics$genre %in% genres_to_keep, ]
#reseting the row indices
rownames(dt_lyrics) <- NULL
# using the function, lyrics_cleaning to clean the lyrics, and then assigning the results to a new column
#### TAKES LONG TO LOAD; CAN LOAD THE DATA FROM load('../output/processed_data.RData')
dt_lyrics$cleaned_lyrics <- sapply(X = dt_lyrics$lyrics, FUN = lyrics_cleaning)
